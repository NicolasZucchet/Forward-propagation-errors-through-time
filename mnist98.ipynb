{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56a37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 98)\n",
      "(96, 98)\n",
      "Epoch 1 | Train Loss: 1.6768, Train Acc: 0.6675\n",
      "Epoch 1 | Test Loss: 1.2289, Test Acc: 0.8193\n",
      "Epoch 2 | Train Loss: 1.0340, Train Acc: 0.8230\n",
      "Epoch 2 | Test Loss: 0.8622, Test Acc: 0.8477\n",
      "Epoch 3 | Train Loss: 0.7877, Train Acc: 0.8439\n",
      "Epoch 3 | Test Loss: 0.6940, Test Acc: 0.8645\n",
      "Epoch 4 | Train Loss: 0.6615, Train Acc: 0.8565\n",
      "Epoch 4 | Test Loss: 0.5976, Test Acc: 0.8739\n",
      "Epoch 5 | Train Loss: 0.5849, Train Acc: 0.8660\n",
      "Epoch 5 | Test Loss: 0.5364, Test Acc: 0.8815\n",
      "Epoch 6 | Train Loss: 0.5333, Train Acc: 0.8726\n",
      "Epoch 6 | Test Loss: 0.4938, Test Acc: 0.8862\n",
      "Epoch 7 | Train Loss: 0.4965, Train Acc: 0.8779\n",
      "Epoch 7 | Test Loss: 0.4624, Test Acc: 0.8889\n",
      "Epoch 8 | Train Loss: 0.4687, Train Acc: 0.8821\n",
      "Epoch 8 | Test Loss: 0.4382, Test Acc: 0.8919\n",
      "Epoch 9 | Train Loss: 0.4472, Train Acc: 0.8850\n",
      "Epoch 9 | Test Loss: 0.4200, Test Acc: 0.8938\n",
      "Epoch 10 | Train Loss: 0.4301, Train Acc: 0.8873\n",
      "Epoch 10 | Test Loss: 0.4049, Test Acc: 0.8953\n",
      "Epoch 11 | Train Loss: 0.4162, Train Acc: 0.8898\n",
      "Epoch 11 | Test Loss: 0.3931, Test Acc: 0.8979\n",
      "Epoch 12 | Train Loss: 0.4047, Train Acc: 0.8920\n",
      "Epoch 12 | Test Loss: 0.3826, Test Acc: 0.8989\n",
      "Epoch 13 | Train Loss: 0.3953, Train Acc: 0.8939\n",
      "Epoch 13 | Test Loss: 0.3745, Test Acc: 0.9008\n",
      "Epoch 14 | Train Loss: 0.3872, Train Acc: 0.8953\n",
      "Epoch 14 | Test Loss: 0.3674, Test Acc: 0.9023\n",
      "Epoch 15 | Train Loss: 0.3805, Train Acc: 0.8970\n",
      "Epoch 15 | Test Loss: 0.3614, Test Acc: 0.9030\n",
      "Epoch 16 | Train Loss: 0.3745, Train Acc: 0.8978\n",
      "Epoch 16 | Test Loss: 0.3560, Test Acc: 0.9038\n",
      "Epoch 17 | Train Loss: 0.3694, Train Acc: 0.8991\n",
      "Epoch 17 | Test Loss: 0.3518, Test Acc: 0.9047\n",
      "Epoch 18 | Train Loss: 0.3649, Train Acc: 0.8996\n",
      "Epoch 18 | Test Loss: 0.3478, Test Acc: 0.9058\n",
      "Epoch 19 | Train Loss: 0.3610, Train Acc: 0.9008\n",
      "Epoch 19 | Test Loss: 0.3439, Test Acc: 0.9053\n",
      "Epoch 20 | Train Loss: 0.3574, Train Acc: 0.9017\n",
      "Epoch 20 | Test Loss: 0.3410, Test Acc: 0.9065\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 1. Load Data\n",
    "def get_datasets(downsampling_factor=8):\n",
    "    \"\"\"Load MNIST and apply downsampling.\"\"\"\n",
    "    train_ds = tfds.load(name='mnist', split='train', as_supervised=True)\n",
    "    test_ds = tfds.load(name='mnist', split='test', as_supervised=True)\n",
    "\n",
    "    def preprocess(image, label):\n",
    "        image = tf.cast(image, tf.float32) / 255.\n",
    "        # Downsample\n",
    "        if downsampling_factor > 1:\n",
    "            shape = tf.shape(image)\n",
    "            n_pixels = shape[0] * shape[1]\n",
    "            image = tf.reshape(image, [n_pixels // downsampling_factor, downsampling_factor])\n",
    "            image = tf.reduce_mean(image, axis=1)\n",
    "        else:\n",
    "            image = tf.reshape(image, [-1]) # Flatten\n",
    "        return image, label\n",
    "\n",
    "    train_ds = train_ds.map(preprocess).cache().shuffle(10000).batch(128).prefetch(1)\n",
    "    test_ds = test_ds.map(preprocess).cache().batch(128).prefetch(1)\n",
    "    return train_ds, test_ds\n",
    "\n",
    "# mnist98 corresponds to a downsampling_factor of 8 (784/8=98)\n",
    "train_ds, test_ds = get_datasets(downsampling_factor=8)\n",
    "train_ds = tfds.as_numpy(train_ds)\n",
    "test_ds = tfds.as_numpy(test_ds)\n",
    "\n",
    "# 2. Define MLP model\n",
    "class MLP(nn.Module):\n",
    "    num_classes: int = 10\n",
    "    num_features: int = 512\n",
    "    num_layers: int = 2\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for _ in range(self.num_layers - 1):\n",
    "            x = nn.Dense(features=self.num_features)(x)\n",
    "            x = nn.relu(x)\n",
    "        x = nn.Dense(features=self.num_classes)(x)\n",
    "        return x\n",
    "\n",
    "# 3. Define loss and accuracy\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return optax.softmax_cross_entropy(logits, one_hot_labels).mean()\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits, labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    metrics = {'loss': loss, 'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "# 4. Training Step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = jnp.array(images), jnp.array(labels)\n",
    "    print(images.shape)\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, images)\n",
    "        loss = cross_entropy_loss(logits, labels)\n",
    "        return loss, logits\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits, labels)\n",
    "    return state, metrics\n",
    "\n",
    "# 5. Evaluation Step\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    images, labels = batch\n",
    "    images = jnp.array(images)\n",
    "    logits = state.apply_fn({'params': state.params}, images)\n",
    "    return compute_metrics(logits, labels)\n",
    "\n",
    "# 6. Training Loop\n",
    "def train_one_epoch(state, dataloader):\n",
    "    batch_metrics = []\n",
    "    for batch in dataloader:\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    epoch_metrics_np = jax.device_get(batch_metrics)\n",
    "    epoch_summary = {\n",
    "        k: np.mean([m[k] for m in epoch_metrics_np])\n",
    "        for k in epoch_metrics_np[0]\n",
    "    }\n",
    "    return state, epoch_summary\n",
    "\n",
    "def evaluate_model(state, test_ds):\n",
    "    metrics = []\n",
    "    for batch in test_ds:\n",
    "        metric = eval_step(state, batch)\n",
    "        metrics.append(metric)\n",
    "    \n",
    "    metrics_np = jax.device_get(metrics)\n",
    "    summary = {\n",
    "        k: np.mean([m[k] for m in metrics_np])\n",
    "        for k in metrics_np[0]\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# Initialization\n",
    "key = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones([1, 98]) # 784/8 = 98\n",
    "]) # MLP(num_features=512, num_layers=1)\n",
    "params = model.init(key, dummy_input)['params']\n",
    "tx = optax.adam(1e-3)\n",
    "state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    state, train_metrics = train_one_epoch(state, train_ds)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {train_metrics['loss']:.4f}, Train Acc: {train_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    test_metrics = evaluate_model(state, test_ds)\n",
    "    print(f\"Epoch {epoch} | Test Loss: {test_metrics['loss']:.4f}, Test Acc: {test_metrics['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13932840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
